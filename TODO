# This file is automatically generated by generate_todo.py.
# Files that start with an underscore ("_") have been excluded.

./parsimony/estimators.py:
-------------------------
92: # TODO: Make all estimators implement this method!
93: # @abc.abstractmethod

113: # TODO: Make all estimators implement this method!
114: # @abc.abstractmethod

125: # TODO: Is this a good name?

139: # TODO: Why is this here? Move to InformationAlgorithm?

273: # TODO: Should we use a seed here so that we get deterministic results?

385: # TODO: Should we use a seed somewhere so that we get deterministic
386: # results?

501: # TODO: Should we use a seed here so that we get deterministic results?

621: # TODO: Should we use a seed here so that we get deterministic results?

804: # TODO: Should we use a seed here so that we get deterministic
805: # results?

833: # TODO: Should we use a seed here so that we get deterministic
834: # results?

1009: # TODO: Should we use a seed here so that we get deterministic results?

1340: # TODO: Should we use a seed here so that we get deterministic results?

1531: # TODO: Should we use a seed here so that we get deterministic results?

1651: # TODO: Should we use a seed here so that we get deterministic results?

1776: # TODO: Should we use a seed here so that we get deterministic results?

1946: # TODO: Should we use a seed here so that we get deterministic results?

2027: # TODO: Should we use a seed here so that we get deterministic results?

2200: # TODO: Should we use a seed here so that we get deterministic results?

2606: # TODO: Add determinism through a random_state?

2739: # TODO: Should we use a seed here so that we get deterministic
2740: # results?
2741: #                if w is None or k > 0:

2957: # TODO: Should we use a seed here so that we get deterministic
2958: # results?
2959: #                if w is None or k > 0:

./parsimony/algorithms/algorithms.py:
------------------------------------
206: # TODO: What if multiple maxs?

216: # TODO: Necessary to loop over those from the loop above?
217: # Loop over all possible i1 in random order:

./parsimony/algorithms/bases.py:
-------------------------------
60: # TODO: Replace the one in BaseAlgorithm.

./parsimony/algorithms/cluster.py:
---------------------------------
110: # TODO: Warn if repeat > 1?

152: mu = global_mean  # TODO: Correct solution?

./parsimony/algorithms/nipals.py:
--------------------------------
50: # TODO: Add information about the runs.

./parsimony/algorithms/proximal.py:
----------------------------------
348: # TODO: Warn if G_new < -consts.TOLERANCE.

375: else:  # TODO: Fix this!

574: # TODO: Warn if gap_mu < -consts.TOLERANCE.

984: # TODO: Investigate what is a good default value here!

1042: y_new = x_new  # TODO: Allow a linear operator here.

1119: # TODO: Investigate what good default value are here!

1171: # TODO: Investigate what good default values are here!

1224: # TODO: Investigate what is a good default value here!

1262: # TODO: Does the weights really matter when the function is the
1263: # indicator function?

1296: # TODO: Investigate what is a good default value here!

./parsimony/algorithms/utils.py:
-------------------------------
42: # TODO: This class should be replaced with Enum.

387: # TODO: We already have f_mid, so we can return a better approximation
388: # here!

478: # TODO: Handle the other cases!

490: # TODO: We seek a root, i.e. where f(x) = 0. The stopping criterion
491: #       should (could?) thus be abs(f(x)) <= eps!

510: if abs(x - x_) <= self.eps:  # TODO: Stopping criterion. See above!

654: # TODO: Be clever if we cannot fit self._K in memory!

./parsimony/functions/combinedfunctions.py:
------------------------------------------
43: # TODO: Add penalty_start and mean to all of these!

1016: # TODO: This is not good. Solve this better!

1657: # TODO: This is not a good solution. Can we solve this in a better way?

1709: # TODO: Use max_iter here!!

1759: # TODO: Kernelise this function! See how I did in
1760: # LinearRegressionL1L2TV._beta_hat.

1811: # TODO: Add this function or refactor API!

2067: # TODO: This is not a nice solution. Can we solve it better?

./parsimony/functions/losses.py:
-------------------------------
191: # TODO: Inherit from LinearRegression and add an L2 constraint instead!

371: # TODO: Make the weights sparse.
372: # weights = np.eye(self.X.shape[0])

374: # TODO: Allow the weight vector to be a list.

482: # TODO: Use RankOneSVD for speedup!

484: self._L = np.max(s) ** 2.0  # TODO: CHECK

648: PWX = 0.5 * np.sqrt(self.weights) * self.X  # TODO: CHECK WITH FOUAD
649: # PW = 0.5 * np.eye(self.X.shape[0]) ## miss np.sqrt(self.W)
650: # PW = 0.5 * np.sqrt(self.W)
651: # PWX = np.dot(PW, self.X)
652: # TODO: Use RankOneSVD for speedup!

654: self._L = np.max(s) ** 2.0  # TODO: CHECK

659: self._L += self.k  # TODO: CHECK

677: # TODO: Handle mean here?

1116: # TODO: This needs some serious speed-ups!

1182: # TODO: This needs some serious speed-ups!

./parsimony/functions/penalties.py:
----------------------------------
225: # TODO: BUG: i may be equal to p => IndexError: list index out of range

228: # TODO: This should not be able to happen! Do we know it doesn't?

232: # TODO: This should not be able to happen! Do we know it doesn't?

600: # TODO: Check if this is correct!

2172: # TODO: Implement this!

2181: # TODO: Implement this!

./parsimony/functions/properties.py:
-----------------------------------
162: # TODO: Should all constraints have the projection operator?

262: # TODO: Remove.

463: # TODO: Should L by default take a weight vector as argument?

828: # TODO: This only work if the elements of self._A are scipy.sparse. We
829: # should allow dense matrices as well.

835: # TODO: Add max_iter here!

./parsimony/functions/multiblock/losses.py:
------------------------------------------
1132: # TODO: Check instead if it is a numpy array.

./parsimony/functions/nesterov/grouptv.py:
-----------------------------------------
157: # TODO: This only work if the elements of self._A are scipy.sparse. We
158: # should allow dense matrices as well.

164: # TODO: Add max_iter here!

./parsimony/functions/nesterov/l1tv.py:
--------------------------------------
67: # WARNING: Number of non-zero rows may differ from p.

150: # TODO: Instead of p, this should really be the number of non-zero
151: # rows of A.

162: # TODO: Add max_iter here!!

269: # TODO: Do we need to take the number of variables here?
270: # Why not use np.prod(shape) + penalty_start instead and save a parameter?

300: # TODO: Do we need to take the number of variables here?
301: # Why not use np.prod(shape) + penalty_start instead and save a parameter?

./parsimony/functions/nesterov/tv.py:
------------------------------------
162: # TODO: This only work if the elements of self._A are scipy.sparse. We
163: # should allow dense matrices as well.

166: # TODO: Instead of p, this should really be the number of non-zero
167: # rows of A.

177: # TODO: Add max_iter here!

./parsimony/utils/consts.py:
---------------------------
20: # TODO: MAX_ITER is heavily algorithm-dependent, so we have to think about if
21: # we should include a package-wide maximum at all.

./parsimony/utils/linalgs.py:
----------------------------
513: # TODO: Put in compiled code for speed.

536: # TODO: Do this instead: In this case x0 is found trivially and we
537: # recurse to a problem of order n-1.

546: # TODO: Use algorithm for banded matrices instead!

./parsimony/utils/plots.py:
--------------------------
96: # TODO: Add the other cases.

./parsimony/utils/stats.py:
--------------------------
126: value = 1.0  # TODO: Is this really correct?

./parsimony/utils/utils.py:
--------------------------
25: # TODO: This depends on the OS. We should try to be clever here ...

28: time = time_cpu  # TODO: Make it so that this can be changed by settings.

